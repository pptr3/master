{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning problem\n",
    "Can we see learning problems (= the task of creating a model which is created by a learning algorithm) in the same way we described the computational problems until now (receiving an input and giving an output)?\n",
    "\n",
    "YES:\n",
    "\n",
    "For the learning problems we have:\n",
    "\n",
    "- input:\n",
    "    - EX(c,D)\n",
    "    - error parameter \"epsilon\" (optional)\n",
    "    - confidence parameter \"delta\" (optional).\n",
    "\n",
    "- output:\n",
    "   - A model (= classifier= \"hypothesis concept\"= \"h\").\n",
    "\n",
    "Note these important things:\n",
    "\n",
    "- EX(c,D) is also called \"oracle\". It's a procedure which the learning algorithm can ideally call as many times as it wants. \"c\" is the classifier used to classify the data and \"D\" is the data distribution. IT'S JUST A FUCKING FANCY WAY TO SAY THAT THE DATA IS LABELED AND EACH INSTANCE HAS BEEN INDEPENDENTLY EXTRACTED FOLLOWING THE DATA DISTRIBUTION D.\n",
    "\n",
    "- the error parameter \"epsilon\" is the maximum probability error which we want to allow to the classifier h.\n",
    "\n",
    "- the confidence parameter is the confidence with which we up-bound the probability error. More correctly \"delta\" is used as \"confidence = 1- delta\".\n",
    "\n",
    "- by giving more data points is possible to reduce epsilon and delta.\n",
    "\n",
    "- The input is given to the LEARNING ALGORITHM \"A\", which will output the classifier. We call the classifier \"h\".\n",
    "\n",
    "- The data is labeled by a certain rule, called concept, which is unknown to A. But what A knows it's the kind of rule used, also called the concept class, so we want to find the rule/concept which has the capability to classify instances as the concept used to label them. This is not possible usually but we can get close to it. We call the concept used to label the data \"T\" or \"c\" or \"target concept\".\n",
    "\n",
    "- Each instance presented to the algorithm A is \"extracted from a set of possible instances\" following a rule called \"data distribution\". The Algorithm doesn't know this data distribution. Could the goodness of the output of the algorithm A (so the classifier h) depend on the data distribution? YES! So how can we evaluate the classifier h independently from the data distribution? By computing the error assuming that the instances given to evaluate it are extracted in the same way as the ones used to learn. We call the data distribution \"D\".\n",
    "\n",
    "- the algorithm A can be trEated as a normal algorithm which we can implement with a TM since input and output can be encoded into binary strings.\n",
    "\n",
    "Can we express somehow the goodness of the algorithm A (not computing an accuracy given by empirical tests)?\n",
    "\n",
    "YES:\n",
    "\n",
    "ERROR PROBABILITY (D,c) = Pr (x<-D) [h(x) != c(x)].  \n",
    "\n",
    "Where:\n",
    " - D= data distribution \n",
    " - x = data instance.\n",
    " - c= target concept= classifier used to label the data. \n",
    " - h=classifier given by the learning algorithm. \n",
    "\n",
    "- Meaning: the probability of error is the probability that an instance x, to be classified, selected by the distribution D, is in the region in which h does a wrong classification.\n",
    "\n",
    "- This is the expression of the error probability of the concept/classifier \"h\" given as output from the algorithm A. NOTE THAT IT DEPENDS ON THE DISTRIBUTION USED TO SELECT THE DATA INSTANCES \"x\" TO BE CLASSIFIED.\n",
    "\n",
    "- How can I improve the quality of the classifier \"h\"? BY DOING THE LEARNING WITH MORE DATA POINTS. NOTE ANYWAY THAT ALSO IF THE NUMBER OF DATA POINTS IS HUGE, IF THE DATA DISTRIBUTION FROM WHICH COME THE NEW INSTANCES TO BE CLASSIFIED IS DIFFERENT FROM THE ONE USED TO DO THE LEARNING, THEN THE ERROR WILL PROBABLY BE MUCH HIGHER!\n",
    "\n",
    "# Example: Abfp Algorithm\n",
    "\n",
    "Imagine to have a collection of points in the R^2 space. Now imagine a rectangle (with sides parallel to the axis) which includes some of them. The ones included are called \"positive\", the others \"negative\". Now imagine to have the task to decide such rectangle only by observing the points which are presented to you. In this case the original rectangle used to label the data points, presented to you, is the target concept \"c\". Which data points are presented to you depends on the data distribution D. How can you find a rectangle which does the same classification as the target concept? (Or at least a small error).\n",
    "\n",
    "This is the task of an algorithm A. An example could be the so called Abfp algorithm, which simply decideS the output rectangle as the smallest one including all the positive data points, let's call it \"h\". \n",
    "\n",
    "Now the question is, if the rectangle h is different from c, then it is a bad result? Not necessarily. Depending on the distribution it could be a good result. Why? Imagine that there's a gap between h and c. But what if the data distribution is such that is never asked to classify data points which are in that region? Then the error would be zero also if h and c are different!!\n",
    "\n",
    "That's why to evaluate the goodness of the concept h we must compute the ERROR PROBABILITY which says what is the probability that the data distribution asks to classify a data point x which is in the region in which h(x) has a different result from the classification c(x).\n",
    "\n",
    "THEOREM:\n",
    "\n",
    "For every distribution D, for every 0 < ε < 1/2 and for every 0 < δ < 1/2, if m ≥ 4/ε ln(4/δ), then:\n",
    "\n",
    "Pr d∼_D_m [error D,T(Abfp(T(d)) < ε] > 1−δ\n",
    "\n",
    "It looks complicated but it's pretty simple. This is the description of each part of the expression:\n",
    "\n",
    "- error D,T(Abfp(T(D)) it's the error probability which we described before. It is the probability of the error of the classifier given as output from the learning algorithm \"Abfp\". The Abfp algorithm recives as input the dataset d (labeled by the classifier T), composed by m instances!!!!  \n",
    "\n",
    "- Pr d∼_D_m means simply that the expression is about the probability depending on the dataset d of which each instance has been extracted INDEPENDENTLY following the data distribution D. The number of instances is m.\n",
    "\n",
    "- \"error D,T(Abfp(T(d)) < ε\" means that the error probability is lower than a certain value epsilon. As you can see the value epsilon is between 1/2 ( not more otherwise the classificator h is even worse than the random one) and 0 ( can't be exactly 0, because there's always at least a small difference between h and c.\n",
    "\n",
    "- Pr d∼_D_m [...] > 1−δ is expressing a confidence about the expression [...].\n",
    "\n",
    "- So the overall expression is a confidence (expressed as a probability) about upper-bound limit imposed to the error probability.\n",
    "\n",
    "- NOTE: THE OVERALL THEOREM IS SAYING THIS: YOU CAN HAVE A CERTAIN CONFIDENCE (1-DELTA) ABOUT THE UPPER BOUND LIMIT TO OF THE ERROR PROBABILITY IF the number of instances in the data m ≥ 4/ε ln(4/δ) !! Which is a great result because if you notice it means that if you want a certain quality of the classifier you need to increase the number of instances with a proportion which is polynomial (wrt the confidence parameter and error parameter)!! Indeed the expression can be seen as 4/n ln(4/n) = O(n ln(n))= O(n^2).\n",
    "\n",
    "- Note that this theorem, as we'll see later, is stating that the concept class of the rectangles in R^2 is EFFICIENTLY PAC LEARNABLE, SINCE THERE'S AN ALGORITHM WHICH NEEDS A NUMBER OF INSTANCES (WHICH IS RELATED TO THE TIME OF COMPUTATION, BECAUSE THE MORE THE DATA THE MORE THE TIME NEEDED TO OUTPUT THE MODEL) DEPENDING ON THE ACCURACY DESIRED, POLYNOMIALLY!!\n",
    "\n",
    "- Note that it's possible to say that the classifier h can become better increasing the number of instances, independently on the data distribution ONLY BECAUSE WE'RE SAYING THAT the same data distribution is used both to generate data to do the learning and also to do the evaluation.\n",
    "\n",
    "- As you'll better understand later, this theorem can also be resumed with this sentence: \"The concept-class of axis-aligned rectangles over R^2[0,1] is efficiently PAC-learnable.\"\n",
    "\n",
    "# FORMAL NOTATION:\n",
    "We have already introduced some normal notation, like the term \"concept\", here we describe more in detail the notation used in computational learning theory:\n",
    "\n",
    "- \"Instance/Input space X\":\n",
    "   Is the set of (encoded) objects that the classifier must classify. We use in general input spaces like R^2 or {0,1}^n.\n",
    "   \n",
    "-  \"Concepts\":\n",
    "   Are subsets of X. This subset contains objects which satisfy a certain property/rule. That's why a concept can be seen as a property. Note that a concept can also be seen as a boolean function which takes an object as input and outputs 1 if the property is satisfied. In the previous example the concept was the rectangle, indeed objects within it were classified as positive. Note that the concept used to label the data, also called \"target concept\"/ \"T\"/ \"c\", is unknown. Note that the output of the learning algorithm A is a concept, called \"hypothesis concept\"/\"h\". Another example of concept can be a Neural Network (with weights and biases fixed).\n",
    "   \n",
    "- \"Concept class C\":\n",
    "  It's a collection of concepts, namely a subset of the powerset of X. For instance a concept can be the a particular rectangle. A concept class can be \"all the rectangles\". Note that a concept class could also add an additional property in order to restrict the set of concepts considered for instance \"all the rectangles with sides aligned with the axis\". Note that the learning algorithm A doesn't know the target concept c BUT KNOWS THE CONCEPT CLASS to which h must belong. In other words the learning algorithm knows if it must produce a model which is a rectangle, or a Neural Network and so on.\n",
    "\n",
    "- \"learning algorithm A\":\n",
    "   It's the algorithm which receives as input the data and outputs the model. We've already described it at the beginning of this notebook. Here I want to point out an example: SGD (Stochastic Gradient Descent) is an example of learning algorithm which is used to produce concepts like Neural Networks (actually Neural Networks can be seen as representation class of the vectors of real values R^n).\n",
    "   \n",
    "- \"Representation class\":\n",
    "   Is the representation of a class of concepts, where each concept is represented as a a symbolic encoding of the respective set or function. The number of bits necessary to encode the concept c into the representation class is called size(c).\n",
    "   Consider a class of concepts defined by the satisfying assignments of boolean formulae. A concept from this class - that is, The set of satisfying assignments for some boolean formula F - can be represented by the formula F itself, by a truth table, or by another boolean formula F' that is logically equivalent to F. Although all of these are representations of the same underlying concept, they may differ radically in representational size.\n",
    "   Examples of representation class to represent Xn={0,1}^n:\n",
    "        \n",
    "        -  CL = Conjunction of Literals.\n",
    "        \n",
    "        -  k-CNF.\n",
    "        \n",
    "        -  k-DNF.\n",
    "        \n",
    "   Example of representation class to represent R^n:\n",
    "   \n",
    "        - some kind of Neural Networks.\n",
    "\n",
    "# Concept Class (efficiently) PAC learnable:\n",
    "PAC = Probably Approximately Correct.\n",
    "\n",
    "Let C be a concept class over the instance space X. We say that C is PAC learnable iff there is an algorithm A such that for every c ∈C, for every distribution D, for every 0 < ε < 1/2 and for every 0 < δ < 1/2:\n",
    "\n",
    "Pr[errorD,c(A(EX(c,D),ε,δ)) < ε] > 1−δ \n",
    "\n",
    "where the probability is taken over the calls to EX(c,D), which means that depend on the extraction of the instances done following the data distribution D.\n",
    "\n",
    "# Efficiently PAC learnable definition (which doesn't take into account the size f the concept class):\n",
    "- If the time complexity of A is bounded by a polynomial in 1/ε and 1/δ, we say that C is EFFICIENTLY PAC learnable.\n",
    "  - example: The concept-class of axis-aligned rectangles over R^2[0,1] is efficiently PAC-learnable.\n",
    "\n",
    "# Efficiently PAC learnable definition:\n",
    "- If the time complexity of A is bounded by a polynomial in n,size(c), 1/ε and 1/δ, we say that THE REPRESENTATION CLASS \"..\" OF C is EFFICIENTLY PAC learnable.\n",
    "  - example: The representation class of boolean conjunctions of literals (CL) is efficiently PAC-learnable.\n",
    "\n",
    "Note:\n",
    "- The time complexity of A is measured taking into account the number of calls to EX(c,D) = number of instances used to do the learning.\n",
    "\n",
    "- \"n\" is the length of the set of variables/values of each instance. For example an instance could be a boolean vector/boolean assignment (in that case the input space is called Xn = {0,1}^n) , or a vector of real numbers of length n (in that case the input space is called Xn=R^n).\n",
    "\n",
    "- size(c) depends on the representation class chosen to encode each instance, namely is the number of bits per instance. \n",
    "\n",
    "- The hypothesis h from C of the PAC learning algorithm is thus \"approximately correct\" with high probability, hence the name Probably Approximately Correct (PAC) learning.\n",
    "\n",
    "- The error probability is about the probability that an instance which will be wrongly classified will be presented. While the confidence parameter is about the probability that a good h will be output from the learning algorithm A.\n",
    "\n",
    "- The PAC learnability is a property of a class of concepts. It depends on the existence of a particular learning algorithm with some great properties: it is possible to reach any accuracy (with an high confidence about it), for any concept and for any distribution. Efficient PAC learnable is something even more great: does exist an algorithm with the former properties, which increases the accuracy (and the confidence) with a polynomial relation wrt the number of instances used (= number of calls to EX(c,D)), and their encoding/representation.\n",
    "\n",
    "More details:\n",
    "\n",
    "- We know that conjunctions of literals are eﬃciently learnable. But they are highly incomplete as a way to represent boolean functions.\n",
    "\n",
    "- An algorithm which could work with the CL representation class is the one which starts from a concept h made of:\n",
    "\n",
    "   x1 ^ not(x1) ^ x2 ^ not(x2) ^ .... ^ xn ^ not(xn)\n",
    "   \n",
    "   which each time receives an input data of the form (xi^xj^not(xk)^..., 0 ) where 0 means that the assignment doesn't satisfy the formula F, then the data is discarded. Instead each time the input data is (x1^x2^not(x3)^..., 1 ) then for each i, if xi = 0, we delete xi from h, and if xi = 1, we delete not(xi) from h. ( Thus, our algorithm deletes any literal that \"contradicts\" the positive data. )\n",
    "\n",
    "- A 3-term DNF formula over n bits (= a propositional formula in the form T1 ∨T2 ∨T3, where each Ti is a conjunction of literals over x1,...,xn, which is in a sense, the dual to 3CNFs) is more expressive than conjunctions of literals (CL), but still not universal. Anyway ALSO IF THE CONCEPT IS THE SAME AND CHANGES ONLY THE REPRESENTATION, THEN THE PROPERTY OF EFFICIENTLY PAC LEARNABILITY CAN BE NOT VALID!! INDEED WE SAW THAT THE REPRESENTATION CLASS \"CL\" IS EFFICIENTLY PAC LEARNABLE, WHILE FOR THE REPRESENTATION CLASS 3-term DNF (WHICH IS A DIFFERENT REPRESENTATION CLASS FOR THE SAME CONCEPT, NAMELY THE BOOLEAN VECTORS) THERE there's this theorem:\n",
    "   If NP != RP, then the representation class of 3-term DNF formulas is not eﬃciently PAC learnable.\n",
    "  \n",
    "   Where RP is the class of randomized algorithms which is widely believed to be different from NP.\n",
    "   \n",
    "   \n",
    "- Imagine to classify images representing green vs yellow flowers. If the kind of Neural Network you're using is efficiently PAC learnable, are you sure they'll work well? Not really: YOU SHOULD NEED TO BE SURE THAT THE DATA YOU'RE USING HAS BEEN LABELED BY A CONCEPT WHICH IS CAPTURED BY A NEURAL NETWORK TOO!! THE POINT IS THAT YOU DON'T KNOW IT!!! If you wanna make sure that class concept for that data  you NEED TO DO EXPERIMENTS. \n",
    "\n",
    "- The professor says: PAC LEARNABLE CAN BE SEEN FROM ANOTHER POINT OF VIEW: IF YOU FIX THE RAPRESENTATION CLASS AND IF YOU ASSUME THAT YOU'RE DATA COMES FROM A CERTAIN RAPRESANTATION CLASS, THEN YOU'RE ALGORITHM WORKS WELL. IN MACHINE LEARNING WE'VE TWO MAIN PROBLEMS:\n",
    "\n",
    "  1) WHICH CONCEPT CLASS TO USE: NEURAL NETWORKS FOR INSTANCE.\n",
    "\n",
    "  2) WHICH ALGORITHMS WORKS WELL: SGD FOR INSTANCE.\n",
    "\n",
    "   PAC LEARNING IS ABOUT ANSEWRING TO THE SECOND PROBLEM.\n",
    "\n",
    "- We also saw two theorems about Neural Networks, showing that two different kind of Neural Networks can be efficient PAC learnable or not (in the example the more expressive wasn't efficient PAC learnable).\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
