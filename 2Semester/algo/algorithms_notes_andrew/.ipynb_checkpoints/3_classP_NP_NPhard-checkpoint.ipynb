{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main points:\n",
    "In this module we'll focus on these points:\n",
    "\n",
    "- Problem Y can't be solved by any algorithm X.\n",
    "\n",
    "- Any algorithm X solving the problem Y is bound to be inefficient or not accurate.\n",
    "\n",
    "- Knowing what are the limits of a problem, give us the opportunity to look for the best solution possible (and to don't waste time by trying to solve something impossible).\n",
    "\n",
    "\n",
    "ToC = Theory of Computation:\n",
    "\n",
    "- (Until 60s) Computability theory: is this task computable?\n",
    "\n",
    "- (From 60s) Computational complexity theory: Efficiency (task solvable in a certain amount or time and/or working memory).\n",
    "  - something which is ineffiecient could be computable, but for us is unpractical.\n",
    "  \n",
    "\n",
    "\n",
    "Distintion with two important concepts:\n",
    "\n",
    "- **Computational task**: is the problem.\n",
    "\n",
    "- **Computational process**: is the algorithm to find the solution to the problem. The same task can have many processes (some efficient and some not) and some task can have no solution/process.\n",
    "\n",
    "\n",
    "Example1: \n",
    "\n",
    "- Task: multiply a*b both expressable with n digits, by performing operations on digits.\n",
    "\n",
    "   - Process1 : \"RepeatedAddition\"=compute a*b = a+a+a... (b times). Each sum can be thought as linear, O(n), so in total the total number of elementary arithmetical steps is = b*n.\n",
    "\n",
    "   - Process2 : \"Gridmethod\" = the so called direct algorithm taught at elementary school, it takes n*n elementary steps.\n",
    "\n",
    "Which one is more efficient? to understand it you must ask what is the relation between b and n. Indeed b depends exponentially on n! i.e. at most 10^n − 1. (we're considering digits in decimal, not in binary).\n",
    "\n",
    "SO THANKS TO THE SECOND PROCESS WE HAVE DISCOVERED THAT THE TASK IS OF CLASS P. NOTE: THE TASK IS WHAT IS CLASSIFIED, NOT THE PROCESS!\n",
    "\n",
    "\n",
    "Example2:\n",
    "\n",
    "- Task: given a set L of candidate invitees, and a list I ⊆ L × L of incompatible pairs of candidate invitees, find the largest subset of L composed of compatible invitees.\n",
    "\n",
    "  - process1: A process that is for obvious reasons a correct way to accomplish the task above consists in considering all possible subsets of L, and check for the presence of incompatibilities in each of them, at the same tracking their size.\n",
    " \n",
    "If L has n elements, how many subset does L have? It turns out to be 2n, which is impractical. At the moment are not known better solutions, so the task is classified as NP.\n",
    "BUT IS IT NOT PROVED THAT WE CAN'T DO BETTER. If we manage to do significantly better, we would have solved the question of whether NP is equal to P.\n",
    "\n",
    "We have to clarify two things: what is P and NP precisely? And why just proving that this example of the wedding problem is P then proofs that all NP are P? (the last question is answered by the NP completeness theorem).\n",
    "\n",
    "# Intro to complexity classes:\n",
    "\n",
    "EVERYTHING WE'RE GOING TO SEE IS A CLASSIFICATION BASED ON THE TM. HOWEVER WHEN PEOPLE TALK ABOUT THE COMPUTATIONAL COST OF AN ALGORITHM THEY IMPLICITLY MEAN THE COMP. COST. BASED ON HIGHER LEVEL MODELS (TYPICALLY THE RAM). SO IT'S BETTER IF YOU TAKE A LOOK AT THAT, BUT ACTUALLY IS WHAT YOU IMPLICITLY DO USUALLY: operations like sum, product, division are considered with cost O(1) (while in turing machines they have cost O(n)), instead scanning a string/list of length n takes O(n) in both kind of models. THE COMPLEXITY COST ANYWAY CAN BE SENSED BY WRITING A PSEUDOCODE OF THE PROCESS, THAT PSEUDOCODE MUST BE WRITTEN THINKING ABOUT THE COMPUTATIONAL MODEL CONSIDERED. NOTE THAT HERE WE DISCUSS A CLASSIFICATION WHICH IS BASED ON TM, BUT IS RELATED WITH ANY OTHER COMPUTATIONAL MODEL, THAT'S WHY IT IS SO IMPORTANT.\n",
    "\n",
    "Task = Language. To be more precise Language = Decision Problem = those tasks which have a boolean output (0/1). To be even more precise the language is the task expressed by a set of strings, where each string has an associated output 1.\n",
    "\n",
    "A **complexity class** is a set of TASKS which can be computed within some prescribed resource bounds.\n",
    "The classes are defined basing on TM, but remember that a TM is an algorithm, not a task.\n",
    "\n",
    "Now we see the classes complexity classification for decision problems.\n",
    "\n",
    "\n",
    "# Class P\n",
    "The class P consists of all those decision problems that can be solved on a deterministic sequential machine (a Turing Machine) in an amount of time that is polynomial in the size of the input.\n",
    "\n",
    "resume:\n",
    "\n",
    "- polynomial time algorithms \n",
    "- polynomial time verification of the solution.\n",
    "- decidable problem.\n",
    "- example: the multiplication of two numbers.\n",
    "\n",
    "Note:\n",
    "Why can we base the classification of tasks on TM? <br>\n",
    "**The Curch Thesis** says that every physically realizable computer can be simulated by a TM with a (possibly very large) overhead in time.\n",
    "\n",
    "The algorithms classified as P are considered EFFICIENT. Isn't that strange? It should be strange since a polynomial time could also be $n^{10000}$, and it would be in class P. Cobham's thesis holds that P is the class of computational problems that are \"efficiently solvable\" or \"tractable\". This is inexact: in practice, some problems not known to be in P have practical solutions, and some that are in P do not, but this is a useful rule of thumb. <br>**So why are them considered efficient**? For the following reasons:\n",
    "\n",
    "1) Usually the algorithms computable in polynomial time are at most $n^{2}$ or $n^{3}$  (of course there are exceptions, for instance some Computer Vision algorithm can have T(n) = $n^{8}$, but still are used and relatively effiecient).\n",
    "\n",
    "2) The classification is based on the time needed for any input, so on the worst one. But for some input, some tasks require a time complexity much higher than the average time complexity for the other inputs.\n",
    "\n",
    "3) \"The strong form of the CT thesis\" says that every physically realizable computation model can be simulated by a TM with polynomial overhead (in other words, t steps on the model can be simulated in $t^c$ steps on the TM, where c is a constant that depends upon the model). It means that if the TM computes an algorithm in $t^c$ steps, a real computer could compute it in much less time! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class FP\n",
    "\n",
    "What is it? Is exactly the same thing of the class P, but for \"function problem\". What are the function problem? Are those problems whose output is NOT NECESSARLY only 1/0. Remember this, because there are certain class of functions which can be converted, in a canonical way, from function to a language (so from a problem which takes a string as input and outputs a string, into a problem which simply outpus 0/1), for instance the functions (=problems) of optimization!! note that by optimization function we mean that the optimization problem itself is considered as a function, which taken a mathematical function (converted in string) outputs the variables in which there's the maximum (converted in string), and this holds:\n",
    "- any Language which belongs to P can be transformed in a function which belongs to FP (since of course the Boolean functions which are in P are also in FP).\n",
    "- also some kind of functions (=optim. problems) can be transformed in a language (because the problem becomes: \"is the input above a certain threshold?\"). **In general, however, it is not true that the language associated to a function in FP is also in P**.\n",
    "\n",
    "\n",
    "## Examples of problems in P or FP:\n",
    "\n",
    "All these problems require to scan the list/string/graph a few times at most\n",
    "\n",
    "- Numbers: primality test, exponentiation,..\n",
    "\n",
    "- Strings: string matching (if a short string occurs within into another long one), approximate matching..\n",
    "\n",
    "- Lists: inversion, sorting, find maximum/minimum..\n",
    "\n",
    "- Graphs: reachability (checking whether one vertex is reachable from another vertex, in a directed graph), shortest paths, minimum spanning trees.. \n",
    "\n",
    "- Optimization: Linear Programming. Note: Simplex Algorithm doesn't work in polynomial time in the worst case, so the linear programming problem is in P thanks to other algorithms. But why is the simplex algorithms so famous? Because the average running time is lower than all the other algorithms of linear programming.\n",
    "\n",
    "## How to prove that something is in P or FP:\n",
    "As we did in some exercise you have different ways:\n",
    "- implement/describe formally the TM.\n",
    "- describe informally the TM\n",
    "- write a pseudocode!! NOTE: WHEN YOU WRITE THE PSEUDOCODE ANYWAY YOU MUST THINK ABOUT THE TM.\n",
    "    - EXAMPLE OF THIS: PROVE THAT THE PROBLEM OF MATCHING TWO STRINGS (if one is shorter it means to see if it is contained in the other one) IS IN P.\n",
    "      Solution:\n",
    "      ```python\n",
    "      input = x,y   # i suppose that x>y\n",
    "      \n",
    "      i=0\n",
    "      \n",
    "      while(i< |x| -|y| +1) do:\n",
    "           \n",
    "           if (x[i:i+|y| -1] == y) return True\n",
    "           else i+=1\n",
    "      end\n",
    "      \n",
    "      return False\n",
    "      ```     \n",
    "      Once you've written the pseudocode, how can you say it does the computation in polynomial time??\n",
    "      \n",
    "      You must reason on it:\n",
    "      - the number of iterations is <=|x|\n",
    "      - for each iteration:\n",
    "      \n",
    "          - the instruction cost: With instruction is meant the comparison (x[i:i+|y| -1] == y). To do the comparison with a 2 working tape TM takes O(|y|).\n",
    "          \n",
    "          - the \"intermediate result\"= the intermediate results are all the variables needed like to count something, or to store partial results, in this case the intermediate result is only the variable \"i\". To increment the variable i in the worst case it takes O(log(|x|). (because in the worst case i must represent the number |x| which can be represented with log(|x|) iterations.\n",
    "\n",
    "So the overall cost can be O(|x| * |y|) which is anyway for sure less than O(|x,y|^2) so it is polynomial, or can be O(|x|log(|x|) which again is for sure less than O(|x,y|^2) so the overall cost of the process is polynomial.\n",
    "Note: if the number of iterations and all the instructions and intermediate results are polynomially bounded wrt the INPUT length, then you can say that the algorithm works in polynomial time.\n",
    "      \n",
    "           \n",
    "           \n",
    "## Class EXP and FEXP:\n",
    "\n",
    "Are the same as P and FP, but instead of polynomial the bound is $2^{n^c}$\n",
    "\n",
    "Example: the wedding plan /MIS problem.\n",
    "\n",
    "Is there a class of algorithms which is something between EXP and P? YES! It is NP. Note that it doesn't exist FNP.<br>\n",
    "Note that there are also algorithms which are not solvable in EXP time, for instance the halting problem which is undecidable.\n",
    "\n",
    "**Note**: We proved that P is different from EXP, so it is strictly included. What about NP? Since we know that P is different from EXP, then NP must strictly include P OR strictly be included in EXP. We still don't know between the two options which is the correct one yet.\n",
    "\n",
    "**Theorem** <br>  \n",
    "P ⊆ EXP, FP ⊆ FEXP, these two inclusions are strict.\n",
    "\n",
    "    \n",
    "    \n",
    "# class NP (\"nondeterministic polynomial time\")\n",
    "the class NP consists of all those decision problems whose positive solutions can be verified in polynomial time given the right information. (Or equivalently whose solution can be found in polynomial time on a non-deterministic machine, that's why it is called nondeterministic P). Note:  P ⊆ NP.\n",
    "Example: Consider Sudoku, a game where the player is given a partially filled-in grid of numbers and attempts to complete the grid following certain rules. Given an incomplete Sudoku grid, of any size, is there at least one legal solution? Any proposed solution is easily verified, and the time to check a solution grows slowly (polynomially) as the grid gets bigger. However, all known algorithms for finding solutions take, for difficult examples, time that grows exponentially as the grid gets bigger. **So, Sudoku is in NP (quickly checkable) but does not seem to be in P (quickly solvable)**.\n",
    "\n",
    "resume:\n",
    "\n",
    "- polynomial algorithm unknown until now.\n",
    "- polynomial verification of the solution.\n",
    "- deciable problem.\n",
    "- example: sudoku.\n",
    "\n",
    "**Theorem** <br>  \n",
    "P ⊆ NP ⊆ EXP\n",
    "\n",
    "**Note**: We proved that P is different from EXP, so it is strictly included. What about NP? Since we know that P is different from EXP, then NP must strictly include P OR strictly be included in EXP.\n",
    "\n",
    "Indeed is more interesting the relationship between P and NP because is the relationship between tractable and considered untractable problems.\n",
    "\n",
    "Note: if someone asks you an example of a problem which DOES NOT HAVE a candidate provable in polynomial time YOU DON'T KNOW IT, IF YOU KNEW IT YOU WOULD HAVE PROVED THAT EXP != NP, WHICH IS STILL UNKNOWN. Anyway you can make example of problems which UNTIL NOW do not have a candidate proven!! ! \n",
    "\n",
    "IT MEANS THAT WE DO NOT KNOW A CANDIDATE, BUT WE HAVEN'T PROVED THAT IT DOESN'T EXIST, WE JUST DO NOT KNOW.\n",
    "\n",
    "**Examples problems in NP**\n",
    "\n",
    "Some of these problems are in NP and some are not. Anytime someone asks you if a problem is in P or NP you should ask yourself: CAN I FIND A CERTIFICATE? WHICH MEANS AN OBJECT/NOTION/STRING WHICH I CAN CHECK IN POLYNOMIAL TIME WITH A TM TO MAKE THE LANGUAGE=1!!\n",
    "\n",
    "- Maximum Independent Set. **Not known to be in P**.\n",
    "- Subset Sum. Can i think about a certificate here? Yes: it is the set of indexes, because then I can simply do the sum (of the relative value taken from the set {n1..nm} in polynomial time with a tm and then check if it is = k, which again can be done in polynomial time. **Not known to be in P**.\n",
    "- Composite Numbers. **Known to be in P** thanks to the so-called AKS algorithm.\n",
    "- Decisional Linear Programming. Linear programming, in its decision form (so the output is only 1 or 0), **can be proved to be in P** thanks to, e.g., the Ellipsoid algorithm.\n",
    "- Decisional 0/1 Linear Programming: this is **not known to be in P**!!! Isn't this crazy? In the case the domain is Q which is infinite, the problem is in P, instead in case the domain is just {0,1} the problem is not known to be in P. This is because so far doesn't exist an algorithm able to solve it in polynomial time. This is really cool because shows that also if you add constraints on the domains doesn't mean that the problem is easier (this probably holds only because we don't know yet an algorithm able to efficiently exploit these constraints).\n",
    "\n",
    "\n",
    "\n",
    "# NP complete:\n",
    "We think that the problems belonging to NP but not to P are the ones more difficult. But remember that we don't know yet if P and NP are actually equivalent. So there are algorithms which we know to be in NP, but we don't know if they are in P. This means that is not clever to define it as the border between feasibility and infeasibility, since this set of problems could also be discovered to be empty.\n",
    "\n",
    "So what we can do? Do a classification within the class NP.\n",
    "Some NP problems have the property of NP-completeness (so are called NP complete): A fast solution to any one of them could be used to build a quick solution to any other problem in NP, a property called NP-completeness. (Any NP problem can be transformed into any of the NP-complete problems. Informally, an NP-complete problem is an NP problem that is at least as \"tough\" as any other problem in NP). So if a quick solution is found for a NP-complete problem, then is all the NP problems have a quick solution, then NP=P would be proven. Unfortunately until now it hasn't been found a quick solution for any NP complete problem.\n",
    "Another point of view: if you have a NP problem, you can convert it (\"reduce it\") to a NP-complete problem, and the conversion is done in polynomial time.\n",
    "\n",
    "resume:\n",
    "\n",
    "- polynomial algorithm to find the solution is not necessary.\n",
    "- polynomial verification of the solution.\n",
    "- recognized as more tough than the other NP problem to be solved.\n",
    "- Any other NP problem can be transformed in a NP-complete problem, doing the transformation in polynomial time, so if an NP-complete is solved by using a polynomial algorithm, it would prove that NP=P.\n",
    "- deciable problem.\n",
    "\n",
    "\n",
    "# P vs NP:\n",
    "The P versus NP problem is a major unsolved problem in computer science. It asks whether every problem whose solution can be quickly verified can also be solved quickly. Which is the same as ask if the class P coincide with the class NP.\n",
    "Nowadays 99% of mathematician thinks that P != NP, but it hasn't been proved yet.\n",
    "\n",
    "It is one of the seven Millennium Prize Problems selected by the Clay Mathematics Institute, each of which carries a US$1,000,000 prize for the first correct solution.\n",
    "\n",
    "The relation between the complexity classes P and NP is studied in computational complexity theory, the part of the theory of computation dealing with the resources required during computation to solve a given problem. The most common resources are time (how many steps it takes to solve a problem) and space (how much memory it takes to solve a problem).\n",
    "\n",
    "In such analysis, a model of the computer for which time must be analyzed is required. Typically such models assume that the computer is deterministic (given the computer's present state and any inputs, there is only one possible action that the computer might take) and sequential (it performs actions one after the other).\n",
    "\n",
    "\n",
    "\n",
    "# NP hard:\n",
    "Some NP problems are classified as hard: NP-hardness (non-deterministic polynomial-time hardness) is, in computational complexity theory, the defining property of a class of problems that are informally \"at least as hard as the hardest problems in NP\". A simple example of an NP-hard problem is the subset sum problem. As the complete ones, the NP hard problems have the property that any NP problem can be reduced/transformed in NP hard in polynomial time. BUT THE NP HARD PROBLEMS DO NOT NECESSARLY HAVE THE PROPERTY OF HAVE A QUICK CHECK OF THE SOLUTION. This is why NP complete problems belong to the NP hard, but NP hard contains also more complex algorithms. Of course finding a polynomial algorithm to solve an NP hard problem would mean to find that NP=P, but this is even more difficult that working on NP-complete problems.\n",
    "\n",
    "resume:\n",
    "- Polynomial algorithm unknown until now.\n",
    "- Polynomial verification of the solution only for some of them!\n",
    "- Recognized as at least tough as the NP-complete problems.\n",
    "- Any other NP problem can be transformed in a NP-hard problem, doing the transformation in polynomial time\n",
    "- If an NP-hard is solved by using a polynomial algorithm, it would prove that NP=P.\n",
    "- If it is undecidable, for sure is NP-hard and not NP.\n",
    "\n",
    "This is the overall hierarchy: \n",
    "\n",
    "<img src=\"NP hierarchy.png\" width=50% height=50%>\n",
    "The upper the more difficult the problem. The left side is valid under the assumption that P≠NP, while the right side is valid under the assumption that P=NP\n",
    "\n",
    "Note:\n",
    "- why is it wrong to interprete \"NP\" as NON POLINOMYAL solution? Because it hasn't been proved!! NP stays for Non deterministic problem refering to the fact that the solution would be polynomial in a non-deterministic machine.\n",
    "\n",
    "- why do we do such classifications? To find the non-existence of a efficient solution for a problem is something really rare. That's why the best thing we can do at the moment is do interrelate the problems.\n",
    "\n",
    "\n",
    "**NOTE**: NP-Complete, NP and P are included in EXP, BUT NP-Hard we still don't know!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More:\n",
    "There exist classification based also on different kind of Machines, for instance BPP is the analogous of class P based on PROBABILISTIC TM. BQP is the analogous of class P based on QUANTUM MACHINES."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The wedding plan problem/ MIS problem:\n",
    "Find the list of maximum length of invited among all those which satisfy some incompatibility constraints.\n",
    "\n",
    "We want find an algorithm to solve this, and we want it efficient.\n",
    "\n",
    "Solution:\n",
    "- we need to transform this problem in a mathematical form which extracts only the necessary details: AN UNDIRECTED GRAPH. Each node is an invitate. The edges are the incompatibilities. So the problem becomes to extract the biggest indipenent.\n",
    "\n",
    "Check the definition of Undirected graph in the notebook \"intro\" if needed. In this problem since the incompatibilities define the edges, then the vertices which are neighbours are incompatible. So let's define formally what we mean with neighbourhood of a node: N(v), where v$\\in V$, is the subset of V so defined: {w | {v,w} $\\in$ E}. (it is a subset of V because w $\\in$ for the definition of E).  \n",
    "\n",
    "Thanks to this definition we can define the wedding problem in a really formal form:\n",
    "\n",
    "Given a graph G=(V,E), determine a subset W of V such that:\n",
    "\n",
    "1) for all v$\\in$W : N(v) $\\cap$ W = $\\emptyset$  % which means that no vertex into the result subset W can be be neighbours.\n",
    "\n",
    "2) W has maximum cardinality among all the sets having the property 1.\n",
    "\n",
    "So what about the solution?\n",
    "First of all what are we trying to solve, a language or a function? It's a function because input= graph (which can be encoded in a string), output=set (which can be encoded in a string).\n",
    "We need to encode the graphs and sets in strings. Remember that an undirected graph can be encoded like this: \n",
    "so Gencoded = _n_#_a1_#_b1_#_a2_#_b2_...#_am_#_bm_\n",
    "\n",
    "anyway the problem in this form is a wel known problem/function called MIS = Maximum Independent Set.\n",
    "\n",
    "The question is: MIS is in FP or FEXP?\n",
    "\n",
    "We can write the following pseudocode, (which is a brute force, but it's the best known until now to solve this problem ) tro prove that it is in FEXP:\n",
    "\n",
    "<img src=\"pseudo_MIS.png\" width=50% width=50%>\n",
    "The cost O(|V|^2) comes from the fact that the loop is over all the element of W, which in the worst case can be as big as V, and each iteration contains the intersection which does a comparison between two sets which can be as big as V.\n",
    "\n",
    "Note that the complexity costs of the various steps are not precise, we don't care so much since anyway the outer loop is 2^|V|, so we only care that inside it there's nothing bigger. \n",
    "\n",
    "So the total cost is O(2^|V| * polynomial(|V|)). We want to be more explicit and compare this with the general form of the EXP class time complexity bound which is O($2^{n^c}$), which can be seen with simple passages: O(2^|V| * polynomial(|V|)) = O(2^|V| * 2^|V|) = O($2^{2|V|}$) =  O($2^{|V|^2}$) but we need to relate it to the size of the input!!!! anyway since |V| is littler than |V,E|=n, we can say that the overall cost is O(2^{n^2}), so it belongs to FEXP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIS -> DMIS\n",
    "Can we turn the MIS function in a Language(=decision problem)? It's easy, we just need an algorithm which takes as input also the function MIS and uses it to determine if the given input can be an output of MIS: \n",
    "<img src=\"DMIS.png\" width=50% height=50%>\n",
    "\n",
    "That's why if a function belongs to FEXP then the associate language belongs to EXP. (the vice versa doesn't necessarly holds).\n",
    "\n",
    "Note: this is a canonical way to turn optimization problems into decision problems : by using the output of the function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prove that P $\\subset$ EXP strictly!!! (and the HT theorem)\n",
    "\n",
    "- It's easy to prove that P ⊆ EXP, because any TM which works in polytime works also in exponential time.\n",
    "\n",
    "- We need now to prove that Exp is different from P. We could simply show an example of a problem which is in Exp and not in P (MIS is not enough, you must also prove that it is not possible to solve it in time P, which is not known ywìet actually). But we want to prove it by proving a stronger thing: the Hierarchy Theorem:\n",
    "\n",
    "HT states that if f(n) and g(n) are time-constructable functions ad f(n)log(f(n)) = o(g(n)) then DTIME(f(n)) $\\subset$ DTIME(g(n)) strictly.\n",
    "\n",
    "We prove only a case of the HT theorem: ...  DTIME(n) $\\subset$ DTIME(n^2) strictly.\n",
    "\n",
    "To prove it we need to proof that there's one language L which belongs to DTIME(n^2) but not to DTIME(n).\n",
    "\n",
    "So let's first proof that there's a language L which can be decided in time n^2. We do it by using a particular TM \"D\" which will allow us to reach a contradiction when we'll show that there's another TM \"N\" able to decide the language L in time n. SO the proof is done by diagonalization. This is the proof scheme:\n",
    "\n",
    "<img src=\"HT_scheme.jpg\" >\n",
    "\n",
    "Now let's show how can we use the HT theorem to prove that P $\\subset$ EXP strictly:\n",
    "\n",
    "- It's easy to prove that P ⊆ EXP, because any TM which works in polytime works also in exponential time.\n",
    "\n",
    "- we can finally prove that P!=EXP. Consider the two classes DTIME(2^n) and DTIME($2^{2n}$). Consider f(n)=2^n and g(n)=$2^{2n}$.By doing the limit we can easilly see that f(n)log(f(n)) = o (g(n)) thus thanks to the HT theorem we can say that DTIME(2^n) $\\subset$ DTIME($2^{2n}$). This is great because we can sau this:\n",
    "\n",
    "<img src=\"P_EXP.png\">2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
